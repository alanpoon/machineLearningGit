PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
install.packages("e1071")
library("e1071", lib.loc="~/R/win-library/3.1")
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("rattle")
library(rattle)
summary(segmentationOriginal$Case)
inTrain <- grep("Train",segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
fit <- train(Class~.,data=training,method="rpart")
fancyRpartPlot(fit$finalModel)
predData <- training[1:3,]
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
#TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
#FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
predData[1,c(103,50,85)]=c(23000,10,2)
predData[2,c(103,50,85)]=c(50000,10,100)
predData[3,c(103,50,85)]=c(57000,8,100)
predict(fit,predData)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
head(olive,2)
head(newData,2)
head(newdata,2)
library(caret)
modFit<-train(Species~.,method='rpart',data=training)
modFit<-train(olive~.,method='rpart',data=training)
head(olive,2)
library(caret)
modFit<-train(olive~.,method='rpart',data=training)
inTrain<- createDataPartition(y=olive$Area,p=0.7,list=FALSE)
training<- olive[inTrain,]
testing<-olive[-inTrain,]
inTrain<- createDataPartition(y=olive$Area,p=0.7,list=FALSE)
training<- olive[inTrain,]
testing<-olive[-inTrain,]
modFit<-train(olive~.method='rpart',data=training)
modFit<-train(olive~.method='rpart',data=training)
modFit<-train(olive~.,method='rpart',data=training)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
head(SAheart,2)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(1234)
fit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(fit,trainSA))
missClass(testSA$chd,predict(fit,testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
library("rattle", lib.loc="~/R/win-library/3.1")
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
install.packages("randomForest")
library(randomForest)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
rm(list = ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = factor(vowel.train$y)
vowel.test$y = factor(vowel.test$y)
set.seed(33833)
model_tree = train(y ~ ., data = vowel.train, method = 'rf')
model_gbm = train(y ~ ., data = vowel.train, method = 'gbm')
pred_tree = predict(model_tree, vowel.test)
pred_gbm = predict(model_gbm, vowel.test)
# Get the accuracy for the tree and the gbm
tree_accuracy = sum(pred_tree == vowel.test$y) / length(pred_tree)
gbm_accuracy = sum(pred_gbm == vowel.test$y) / length(pred_tree)
# Get the last part of the answer
agreeSub = vowel.test[pred_tree == pred_gbm,]
pred_comb = predict(model_tree, agreeSub)
comb_accuracy = sum(pred_comb == agreeSub$y) / length(pred_comb)
library(AppliedPredictiveModeling)
library(caret)
library(rattle)
library(forecast)
library(lubridate)
rm(list = ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = factor(vowel.train$y)
vowel.test$y = factor(vowel.test$y)
set.seed(33833)
model_tree = train(y ~ ., data = vowel.train, method = 'rf')
model_gbm = train(y ~ ., data = vowel.train, method = 'gbm')
Q
rm(list = ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y = factor(vowel.train$y)
vowel.test$y = factor(vowel.test$y)
set.seed(33833)
model_tree = train(y ~ ., data = vowel.train, method = 'rf')
model_gbm = train(y ~ ., data = vowel.train, method = 'gbm')
rm(list = ls())
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model_rf = train(diagnosis ~ ., method = 'rf', data = training)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rm(list = ls())
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model_rf = train(diagnosis ~ ., method = 'rf', data = training)
model_gbm = train(diagnosis ~ ., method = 'gbm', data = training)
model_lda = train(diagnosis ~ ., method = 'lda', data = training)
pred_rf = predict(model_rf, training)
pred_gbm = predict(model_gbm, training)
pred_lda = predict(model_lda, training)
comb_data = data.frame(rf = pred_rf, gbm = pred_gbm, lda = pred_lda, diagnosis = training$diagnosis)
model_comb = train(diagnosis ~ ., method = 'rf', data = comb_data)
pred_rf_test = predict(model_rf, testing)
pred_gbm_test = predict(model_gbm, testing)
pred_lda_test = predict(model_lda, testing)
comb_data_test = data.frame(rf = pred_rf_test, gbm = pred_gbm_test, lda = pred_lda_test, diagnosis = testing$diagnosis)
pred_comb_test = predict(model_comb, comb_data_test)
accuracy_rf = sum(pred_rf_test == testing$diagnosis) / length(pred_rf_test)
accuracy_gbm = sum(pred_gbm_test == testing$diagnosis) / length(pred_gbm_test)
accuracy_lda = sum(pred_lda_test == testing$diagnosis) / length(pred_lda_test)
accuracy_comb = sum(pred_comb_test == comb_data_test$diagnosis) / length(pred_comb_test)
accuracy_gbm
accuracy_lda
accuracy_comb
accuracy_rf
setwd('C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8')
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) == 2011,]
tstrain = ts(training$visitsTumblr)
remdata = dat[year(dat$date) > 2011,]
tsrem = ts(remdata$visitsTumblr)
model = bats(tstrain)
pred <- forecast(model, h=length(tsrem),level=c(95))
accuracy(pred, remdata$visitsTumblr)
acc = sum(remdata$visitsTumblr <= pred$upper) / nrow(remdata)
library("lubridate", lib.loc="~/R/win-library/3.1")
dat = read.csv("gaData.csv")
training = dat[year(dat$date) == 2011,]
tstrain = ts(training$visitsTumblr)
remdata = dat[year(dat$date) > 2011,]
tsrem = ts(remdata$visitsTumblr)
model = bats(tstrain)
pred <- forecast(model, h=length(tsrem),level=c(95))
accuracy(pred, remdata$visitsTumblr)
acc = sum(remdata$visitsTumblr <= pred$upper) / nrow(remdata)
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) == 2011,]
tstrain = ts(training$visitsTumblr)
remdata = dat[year(dat$date) > 2011,]
tsrem = ts(remdata$visitsTumblr)
model = bats(tstrain)
pred <- forecast(model, h=length(tsrem),level=c(95))
accuracy(pred, remdata$visitsTumblr)
acc = sum(remdata$visitsTumblr <= pred$upper) / nrow(remdata)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
model = svm(CompressiveStrength ~ ., data = training)
model
pred = predict(model, testing)
RMSE = sqrt(sum((pred - testing$CompressiveStrength)^2))
predins = predict(model, training)
RMSEins = sqrt(sum((predins - training$CompressiveStrength)^2))
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
if (!"trainingData.csv" %in% dir("./")  ) {
if (!"trainingData.csv  %in% dir("./") "){}
print("trainingData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "./trainingData.csv")
}
}
if (!"trainingData" %in% ls()) {
trainingData <- read.csv("./trainingData.csv", sep = ",")
}
dim(trainingData)
head(trainingData, n = 2)
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
if (!"trainingData.csv" %in% dir("./")  ) {
if (!"trainingData.csv  %in% dir("./") "){}
print("trainingData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "./trainingData.csv")
}
}
if (!"trainingData" %in% ls()) {
trainingData <- read.csv("./trainingData.csv", sep = ",")
}
dim(trainingData)
head(trainingData, n = 2)
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
if (!"trainingData.csv" %in% dir("./")  ) {
if (!"trainingData.csv  %in% dir("./") "){}
print("trainingData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "../courseProjectData/trainingData.csv")
}
}
if (!"trainingData" %in% ls()) {
trainingData <- read.csv("../courseProjectData/trainingData.csv", sep = ",")
}
dim(trainingData)
head(trainingData, n = 2)
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
if (!"trainingData.csv" %in% dir("../courseProjectData")  ) {
print("trainingData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "../courseProjectData/trainingData.csv")
}
}
if (!"trainingData" %in% ls()) {
trainingData <- read.csv("../courseProjectData/trainingData.csv", sep = ",")
}
dim(trainingData)
head(trainingData, n = 2)
if (!"testData.csv" %in% dir("../courseProjectData")  ) {
print("testData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "../courseProjectData/testData.csv")
}
}
if (!"testData" %in% ls()) {
testData <- read.csv("../courseProjectData/testData.csv", sep = ",")
}
dim(testData)
head(testData, n = 2)
head(testData,2)
head(trainingData,1)
library(gridExtra)
library(Hmisc)
names(training)
summary(training)
age <- cut2(training$Age,g=10)
flyash <- cut2(training$FlyAsh,g=10)
byAge <- qplot(seq(1,nrow(training)),CompressiveStrength,data=training,col=age)
byFlyAsh <- qplot(seq(1,nrow(training)),CompressiveStrength,data=training,col=flyash)
grid.arrange(byAge,byFlyAsh)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(gridExtra)
library(Hmisc)
names(training)
summary(training)
age <- cut2(training$Age,g=10)
flyash <- cut2(training$FlyAsh,g=10)
byAge <- qplot(seq(1,nrow(training)),CompressiveStrength,data=training,col=age)
byFlyAsh <- qplot(seq(1,nrow(training)),CompressiveStrength,data=training,col=flyash)
grid.arrange(byAge,byFlyAsh)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
range(training$Superplasticizer)
table(training$Superplasticizer==0)
qplot(Superplasticizer,data=training)
qplot(log(Superplasticizer+1),data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(ggplot2)
library(caret)
ncol(training)
which(sapply(adData,class)=="factor")
summary(training$diagnosis)
training$diagnosis = as.numeric(training$diagnosis)
p <- prcomp(training[,grep('^IL',names(training))])
p$rotation[,1:7]
qplot(1:length(p$sdev),p$sdev / sum(p$sdev))
which(cumsum(p$sdev) / sum(p$sdev) <= .9)
(cumsum(p$sdev) / sum(p$sdev))[8]
#Result here
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.8)
summary(trainingData)
modelFit<- train(classe~.,data=trainingData,method='glm')
warnings()
library(caret)
set.seed(32343)
preProc <- preProcess(trainingData[-13],method="pca",thres=.8)
library(caret)
set.seed(32343)
preProc <- preProcess(trainingData,method="pca",thres=.8)
summary(trainingData)
data(BloodBrain)
# one variable has one unique value
## Not run:
preProc <- preProcess(bbbDescr)
summary(bbbDescr)
data(BloodBrain)
# one variable has one unique value
## Not run:
preProc <- preProcess(bbbDescr)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
trainSmall[-13]
head(trainSmall,2)
head(trainingData,2)
preProc <- preProcess(trainingData,method="pca",thres=.8)
library(caret)
set.seed(32343)
preProc <- preProcess((trainingData,
method = c("center", "scale"),
thresh = 0.95,
pcaComp = NULL,
na.remove = TRUE,
k = 5,
knnSummary = mean,
outcome = NULL,
fudge = .2,
numUnique = 3,
verbose = FALSE,
...))
library(caret)
set.seed(32343)
preProc <- preProcess(trainingData,
method = c("center", "scale"),
thresh = 0.95,
pcaComp = NULL,
na.remove = TRUE,
k = 5,
knnSummary = mean,
outcome = NULL,
fudge = .2,
numUnique = 3,
verbose = FALSE)
preProc <- preProcess(trainingData,
method = c("center", "scale"),
thresh = 0.95,
pcaComp = NULL,
na.remove = TRUE,
k = 5,
knnSummary = mean,
outcome = NULL,
fudge = .2,
numUnique = 3,
verbose = FALSE)
head(trainingData,2)
data(BloodBrain)
# one variable has one unique value
## Not run:
preProc <- preProcess(bbbDescr)
preProc
predict(preProc)
predict(preProc,newdata=bbbDescr)
data(BloodBrain)
# one variable has one unique value
## Not run:
preProc  <- preProcess(bbbDescr[1:100,-3])
bbbDescr[1:100,-3]
bbbDescr[,-3]
bbbDescr[,-3]
summary(bbbDescr)
library(caret)
set.seed(32343)
preProc <- preProcess(trainingData,
method = c("center", "scale"),
thresh = 0.95,
pcaComp = NULL,
na.remove = TRUE,
k = 5,
knnSummary = mean,
outcome = NULL,
fudge = .2,
numUnique = 3,
verbose = FALSE)
summary(trainingData)
data(segmentationOriginal)
head(segmentationOriginal,2)
head(segmentationOriginal,3)
