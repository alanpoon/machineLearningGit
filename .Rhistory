testing = mixtures[-inTrain,]
range(training$Superplasticizer)
table(training$Superplasticizer==0)
qplot(Superplasticizer,data=training)
qplot(log(Superplasticizer+1),data=training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(ggplot2)
library(caret)
ncol(training)
which(sapply(adData,class)=="factor")
summary(training$diagnosis)
training$diagnosis = as.numeric(training$diagnosis)
p <- prcomp(training[,grep('^IL',names(training))])
p$rotation[,1:7]
qplot(1:length(p$sdev),p$sdev / sum(p$sdev))
which(cumsum(p$sdev) / sum(p$sdev) <= .9)
(cumsum(p$sdev) / sum(p$sdev))[8]
#Result here
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.9)
preProc
preProc
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.8)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
trainSmall <- data.frame(training[,grep('^IL',names(training))],training$diagnosis)
testSmall <- data.frame(testing[,grep('^IL',names(testing))],testing$diagnosis)
preProc <- preProcess(trainSmall[-13],method="pca",thres=.8)
trainPC <- predict(preProc,trainSmall[-13])
testPC <- predict(preProc,testSmall[-13])
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
install.packages("e1071")
library("e1071", lib.loc="~/R/win-library/3.1")
PCFit <- train(trainSmall$training.diagnosis~.,data=trainPC,method="glm")
NotPCFit <- train(trainSmall$training.diagnosis~.,data=trainSmall,method="glm")
PCTestPredict <- predict(PCFit,newdata=testPC)
NotPCTestPredict <- predict(NotPCFit,newdata=testSmall)
confusionMatrix(PCTestPredict,testSmall$testing.diagnosis)
confusionMatrix(NotPCTestPredict,testSmall$testing.diagnosis)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages("rattle")
library(rattle)
summary(segmentationOriginal$Case)
inTrain <- grep("Train",segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
fit <- train(Class~.,data=training,method="rpart")
fancyRpartPlot(fit$finalModel)
predData <- training[1:3,]
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
#TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
#FiberWidthCh1 = 8;VarIntenCh4 = 100; PerimStatusCh1=2
predData[1,c(103,50,85)]=c(23000,10,2)
predData[2,c(103,50,85)]=c(50000,10,100)
predData[3,c(103,50,85)]=c(57000,8,100)
predict(fit,predData)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
head(olive,2)
head(newData,2)
head(newdata,2)
library(caret)
modFit<-train(Species~.,method='rpart',data=training)
modFit<-train(olive~.,method='rpart',data=training)
head(olive,2)
library(caret)
modFit<-train(olive~.,method='rpart',data=training)
inTrain<- createDataPartition(y=olive$Area,p=0.7,list=FALSE)
training<- olive[inTrain,]
testing<-olive[-inTrain,]
inTrain<- createDataPartition(y=olive$Area,p=0.7,list=FALSE)
training<- olive[inTrain,]
testing<-olive[-inTrain,]
modFit<-train(olive~.method='rpart',data=training)
modFit<-train(olive~.method='rpart',data=training)
modFit<-train(olive~.,method='rpart',data=training)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area~.,data=olive,method="rpart")
pred <- predict(fit,newdata)
fancyRpartPlot(fit$finalModel)
head(SAheart,2)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(1234)
fit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(fit,trainSA))
missClass(testSA$chd,predict(fit,testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
library("rattle", lib.loc="~/R/win-library/3.1")
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
install.packages("randomForest")
library(randomForest)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
if (!"trainingData.csv" %in% dir("../courseProjectData")  ) {
print("trainingData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "../courseProjectData/trainingData.csv")
}
if (!"trainingData" %in% ls()) {
trainingData <- read.csv("../courseProjectData/trainingData.csv", sep = ",")
}
if (!"testData.csv" %in% dir("../courseProjectData")  ) {
print("testData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "../courseProjectData/testData.csv")
}
if (!"testData" %in% ls()) {
testData <- read.csv("../courseProjectData/testData.csv", sep = ",")
}
testData[is.na(testData)]<-0
trainingData[is.na(trainingData)]<-0
jf<-trainingData
jf<-jf[,colSums(jf=="#DIV/0!"||jf=='')==0]
jf<-jf[,colSums(jf=='')==0]
drops <- c("cvtd_timestamp")
tf<-jf[,!(names(jf) %in% drops)]
library(caret)
tf<-downSample(tf,as.factor(tf$classe))
set.seed(32323)
folds<-createFolds(y=tf,k=5,list=FALSE,returnTrain=FALSE)
summary(tf[folds[[2]],])
set.seed(32323)
inTrain<-createDataPartition(y=tf$classe,p=0.75,list=FALSE)
trainModelData<-tf[inTrain,]
sampleTestData<-tf[-inTrain,]
nsv<-nearZeroVar(trainModelData,saveMetrics=TRUE)
nsvToBeDrop<-nsv[nsv$nzv==TRUE,]
drops<-row.names(nsvToBeDrop)
yf<-trainModelData[,!(names(trainModelData) %in% drops)]
pf<-yf[,c(-58,-59,-2)]
uf<-abs(cor(pf))
uf[upper.tri(uf)]<-0
diag(uf)<-0
er<-which(uf>0.8,arr.ind=T)
library(ggplot2)
xName<-names(pf)[c(8)]
yName<-names(pf)[c(5)]
qq<- qplot(get(xName),get(yName),colour=classe,data=yf) + geom_smooth(method='lm',formula=y~x)
acceptableVar<-pf[,!apply(uf,2,function(x) any(x > 0.80)) ]
acceptableVar1<-pf[,sapply(as.vector(row.names(uf)),function(x) match(x,row.names(uf)) %in% c(1,5,6,12,22,25,29,32,33)) ]
data.new<-merge(acceptableVar,acceptableVar1,by='X')
drops <- c("X")
data.new<-data.new[,!(names(data.new) %in% drops)]
### insert back the classe attribute
data.new$classe<-yf$classe
data.new$user_name<-yf$user_name
library(rattle)
library(rpart)
library(rpart.plot)
set.seed(125)
model1<-rpart(classe ~ ., data=data.new, method="class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
ptraining<-predict(model1,sampleTestData)
library(randomForest)
set.seed(125)
model2<-randomForest(classe ~ ., data = data.new, importance = TRUE, ntrees = 10)
ptraining2 <- predict(model2, sampleTestData)
ptraining2
summary(ptraining2)
ptraining
head(ptraining,2)
summary(ptraining)
varImpPlot(model1, type=1)
head(sampleTestData,1)
head(sampleTestData[,-1])
head(sampleTestData[,-1],1)
head(sampleTestData,1)
data(iris)
# this data has 150 rows
nrow(iris)
# look at the first few
head(iris)
# splitdf function will return a list of training and testing sets
splitdf <- function(dataframe, seed=NULL) {
if (!is.null(seed)) set.seed(seed)
index <- 1:nrow(dataframe)
trainindex <- sample(index, trunc(length(index)/2))
trainset <- dataframe[trainindex, ]
testset <- dataframe[-trainindex, ]
list(trainset=trainset,testset=testset)
}
#apply the function
splits <- splitdf(iris, seed=808)
#it returns a list - two data frames called trainset and testset
str(splits)
# there are 75 observations in each data frame
lapply(splits,nrow)
#view the first few columns in each data frame
lapply(splits,head)
# save the training and testing sets as data frames
training <- splits$trainset
testing <- splits$testset
########### Optional: apply to iris data using randomForest ###########
#load the randomForest library. if you havent installed it, run the next line
#install.packages("randomForest")
library(randomForest)
#fit the randomforest model
model <- randomForest(Sepal.Length~.,
data = training,
importance=TRUE,
keep.forest=TRUE
)
print(model)
#what are the important variables (via permutation)
varImpPlot(model, type=1)
#predict the outcome of the testing data
predicted <- predict(model, newdata=testing[ ,-1])
# what is the proportion variation explained in the outcome of the testing data?
# i.e., what is 1-(SSerror/SStotal)
actual <- testing$Sepal.Length
rsq <- 1-sum((actual-predicted)^2)/sum((actual-mean(actual))^2)
print(rsq)
predicted
head(predicted,1)
head(ptraining,1)
head(testing,1)
head(testing[,-1],1)
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
ptraining <- predict(model1, TestTrainingSet, type = "class")
ptraining <- predict(model1, sampleTestData, type = "class")
confusionMatrix(prediction1, sampleTestData$classe)
confusionMatrix(ptraining, sampleTestData$classe)
varImpPlot(model, type=1)
varImpPlot(model2, type=1)
print(model2)
confusionMatrix(ptraining2, sampleTestData$classe)
ptest2<-predict(model2,testData)
ptest2
dim(ptest2)
testData[is.na(testData)]<-0
trainingData[is.na(trainingData)]<-0
jf<-trainingData
jf<-jf[,colSums(jf=="#DIV/0!"||jf=='')==0]
jf<-jf[,colSums(jf=='')==0]
drops <- c("cvtd_timestamp")
tf<-jf[,!(names(jf) %in% drops)]
JF
jf
testData[is.na(testData)]<-0
trainingData[is.na(trainingData)]<-0
jf<-trainingData
jf<-jf[,colSums(jf=="#DIV/0!"||jf=='')==0]
jf<-jf[,colSums(jf=='')==0]
drops <- c("cvtd_timestamp")
tf<-jf[,!(names(jf) %in% drops)]
testData[is.na(testData)]<-0
trainingData[is.na(trainingData)]<-0
jf<-trainingData
##jf<-jf[,colSums(jf=="#DIV/0!"||jf=='')==0]
##jf<-jf[,colSums(jf=='')==0]
jf<-jf[,colSums(is.na(jf)) == 0]
drops <- c("cvtd_timestamp")
tf<-jf[,!(names(jf) %in% drops)]
confusionMatrix(ptraining, sampleTestData$classe)
sampleTestData$classe
ptraining
sampleTestData$classe
ptraining
head(sampleTestData,1)
head(tf,1)
sampleTestData<-tf[-inTrain,]
sampleTestData
setwd("C:/Users/alanpoon/Desktop/coursera/Practical Machine Learning 8/machineLearningGit")
if (!"trainingData.csv" %in% dir("../courseProjectData")  ) {
print("trainingData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "../courseProjectData/trainingData.csv")
}
if (!"trainingData" %in% ls()) {
trainingData <- read.csv("../courseProjectData/trainingData.csv", sep = ",")
}
if (!"testData.csv" %in% dir("../courseProjectData")  ) {
print("testData.csv is there")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "../courseProjectData/testData.csv")
}
if (!"testData" %in% ls()) {
testData <- read.csv("../courseProjectData/testData.csv", sep = ",")
}
testData[is.na(testData)]<-0
trainingData[is.na(trainingData)]<-0
jf<-trainingData
jf<-jf[,colSums(is.na(jf)) == 0]
drops <- c("cvtd_timestamp")
tf<-jf[,!(names(jf) %in% drops)]
summary(jf)
library(caret)
tf<-downSample(tf,as.factor(tf$classe))
set.seed(32323)
folds<-createFolds(y=tf,k=5,list=FALSE,returnTrain=FALSE)
summary(tf[folds[[2]],])
set.seed(32323)
inTrain<-createDataPartition(y=tf$classe,p=0.75,list=FALSE)
trainModelData<-tf[inTrain,]
sampleTestData<-tf[-inTrain,]
summary(sampleTestData)
tf[-inTrain,][,-160]
nsv<-nearZeroVar(trainModelData,saveMetrics=TRUE)
nsvToBeDrop<-nsv[nsv$nzv==TRUE,]
drops<-row.names(nsvToBeDrop)
yf<-trainModelData[,!(names(trainModelData) %in% drops)]
pf<-yf[,c(-58,-59,-2)]
uf<-abs(cor(pf))
uf[upper.tri(uf)]<-0
diag(uf)<-0
er<-which(uf>0.8,arr.ind=T)
library(ggplot2)
xName<-names(pf)[c(8)]
yName<-names(pf)[c(5)]
qq<- qplot(get(xName),get(yName),colour=classe,data=yf) + geom_smooth(method='lm',formula=y~x)
acceptableVar<-pf[,!apply(uf,2,function(x) any(x > 0.80)) ]
acceptableVar1<-pf[,sapply(as.vector(row.names(uf)),function(x) match(x,row.names(uf)) %in% c(1,5,6,12,22,25,29,32,33)) ]
data.new<-merge(acceptableVar,acceptableVar1,by='X')
drops <- c("X")
data.new<-data.new[,!(names(data.new) %in% drops)]
### insert back the classe attribute
data.new$classe<-yf$classe
data.new$user_name<-yf$user_name
library(rattle)
library(rpart)
library(rpart.plot)
set.seed(125)
model1<-rpart(classe ~ ., data=data.new, method="class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
ptraining<-predict(model1,sampleTestData[,-160])
confusionMatrix(ptraining, sampleTestData$classe)
ptraining<-predict(model1,sampleTestData)
confusionMatrix(ptraining, sampleTestData$classe)
head(sampleTestData,1)
head(sampleTestData[,-160],1)
summary(ptraining)
head(ptraining,1)
ptraining<-predict(model1,sampleTestData)
confusionMatrix(ptraining, sampleTestData$classe)
sampleTestData$classe
ptraining
ptraining<-predict(model1,sampleTestData)
predict(model1,sampleTestData)
library(randomForest)
set.seed(125)
model2<-randomForest(classe ~ ., data = data.new, importance = TRUE, ntrees = 10)
#what are the important variables (via permutation)
varImpPlot(model, type=1)
ptraining2 <- predict(model2, sampleTestData)
confusionMatrix(ptraining2, sampleTestData$classe)
ptraining2
model2
model1
library(rattle)
library(rpart)
library(rpart.plot)
set.seed(125)
model1<-rpart(classe ~ ., data=data.new, method="class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
ptraining<-predict(model1,sampleTestData)
confusionMatrix(ptraining, sampleTestData$classe)
predict(model1,sampleTestData,type='class')
ptraining<-predict(model1,sampleTestData,type='class')
confusionMatrix(ptraining, sampleTestData$classe)
source('~/.active-rstudio-document', echo=TRUE)
str(mtcars)
data(mtcars)
str(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
mtcars$am <- factor(mtcars$am,labels=c('Automatic','Manual'))
x<-mtcars$am
y<-mtcars$mpg
lmfit<-lm(y~x)
summary(lmfit)
x<-mtcars$cyl+mtcars$hp+mtcars$wt+mtcars$am
lmfit2<-lm(y~x)
summary(lmfit2)
lmfit2<-lm(formula = mpg ~ cyl + hp + wt + am, data = mtcars)
summary(lmfit2)
boxplot(mpg ~ am, data = mtcars, col = "blue", ylab = "miles per gallon")
lmfit2 <- step(lmfit, direction = "backward")
##summary(lmfit2)
summary(lmfit2)
lmfit<-lm(mpg~.,data=mtcars)
summary(lmfit)
lmfit2 <- step(lmfit, direction = "backward")
##summary(lmfit2)
summary(lmfit2)
help(mtcars)
t.test(mpg ~ am, data = mtcars)
data(mtcars)
t.test(mpg ~ am, data = mtcars)
data(mtcars)
str(mtcars)
mtcars$cyl <- factor(mtcars$cyl)
mtcars$vs <- factor(mtcars$vs)
mtcars$gear <- factor(mtcars$gear)
mtcars$carb <- factor(mtcars$carb)
mtcars$am <- factor(mtcars$am,labels=c('Automatic','Manual'))
t.test(mpg ~ am, data = mtcars)
